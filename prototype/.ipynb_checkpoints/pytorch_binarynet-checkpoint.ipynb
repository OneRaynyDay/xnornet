{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional\n",
    "import math\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# MNIST dataset (images and labels)\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                              transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
    "                                                          ]),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                              transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
    "                                                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarize(torch.autograd.Function):\n",
    "    THRESHOLD_STE = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        We approximate the input by the following:\n",
    "        \n",
    "        input ~= sign(input) * l1_norm(input) / input.size\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.sign() * torch.mean(torch.abs(input))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        According to [Do-Re-Fa Networks](https://arxiv.org/pdf/1606.06160.pdf),\n",
    "        the STE for binary weight networks is completely pass through.\n",
    "        \n",
    "        However, according to [Binary Neural Networks](https://arxiv.org/pdf/1602.02830.pdf),\n",
    "        and [XNOR-net networks](https://arxiv.org/pdf/1603.05279.pdf),\n",
    "        the STE must be thresholded by the following:\n",
    "        \n",
    "        d = d * (-1 <= w <= 1)\n",
    "        \n",
    "        Set THRESHOLD_STE to True/False for either behavior. However, it is suggested\n",
    "        to set it to True because we have seen performance degradations with it = False.\n",
    "        \"\"\"\n",
    "        if Binarize.THRESHOLD_STE:\n",
    "            input, = ctx.saved_tensors\n",
    "            grad_output[input.ge(1)] = 0\n",
    "            grad_output[input.le(-1)] = 0\n",
    "        return grad_output\n",
    "\n",
    "class BinaryLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        Takes in some inputs x, and initializes some weights for matmul,\n",
    "        and performs a bitcount(xor(x, weights)).\n",
    "        \n",
    "        input = (N, M)\n",
    "        weights = (M, K)\n",
    "        \n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to False, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "        \"\"\"\n",
    "        super(BinaryLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n",
    "        \n",
    "        # Initializing parameters\n",
    "        stdv = 1. / math.sqrt(in_features * out_features)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)        \n",
    "\n",
    "    def forward(self, input):\n",
    "        binarize = Binarize.apply\n",
    "        return functional.linear(binarize(input), binarize(self.weight), binarize(self.bias))\n",
    "    \n",
    "class BinaryConvolution2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, bias=True):\n",
    "        \"\"\"\n",
    "        Takes in some inputs x, and initializes some weights for conv filters,\n",
    "        and performs a \"convolution\" by binarizing the weights and multiplying\n",
    "        the inputs by the binarized weights.\n",
    "        \n",
    "        input = (N, C, H, W)\n",
    "        weights = (K, C, H, W) [ to be binarized ]\n",
    "        biases = (K,) [ to be binarized ]\n",
    "        output = (N, K, H, W)\n",
    "        \n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
    "        \n",
    "        NOTE: We skip dilation, groups, etc for now.\n",
    "        \"\"\"\n",
    "        super(BinaryConvolution2d, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(out_channels, in_channels, *(kernel_size, kernel_size)))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Initializing parameters\n",
    "        n = in_channels\n",
    "        n *= kernel_size ** 2 # number of parameters\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        binarize = Binarize.apply\n",
    "        return functional.conv2d(binarize(input), binarize(self.weight), binarize(self.bias), self.stride, self.padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9913,  0.2109,  1.3223]])\n",
      "tensor([[ 0.8415,  0.8415,  0.8415]])\n",
      "6.026494026184082\n",
      "tensor([[-0.3170, -2.3170,  0.0000]])\n",
      "---\n",
      "tensor([[ 1.0230,  0.4426,  1.3223]])\n",
      "tensor([[ 0.9293,  0.9293,  0.9293]])\n",
      "5.439297676086426\n",
      "tensor([[ 0.0000, -2.1414,  0.0000]])\n",
      "---\n",
      "tensor([[ 1.0230,  0.6567,  1.3223]])\n",
      "tensor([[ 1.0007,  1.0007,  1.0007]])\n",
      "4.9960103034973145\n",
      "tensor([[ 0.0000, -1.9987,  0.0000]])\n",
      "---\n",
      "tensor([[ 1.0230,  0.8566,  1.3223]])\n",
      "tensor([[ 1.0673,  1.0673,  1.0673]])\n",
      "4.60985803604126\n",
      "tensor([[ 0.0000, -1.8654,  0.0000]])\n",
      "---\n",
      "tensor([[ 1.0230,  1.0432,  1.3223]])\n",
      "tensor([[ 1.1295,  1.1295,  1.1295]])\n",
      "4.2734761238098145\n",
      "tensor([[ 0.,  0.,  0.]])\n",
      "---\n",
      "tensor([[ 1.0230,  1.0432,  1.3223]])\n",
      "tensor([[ 1.1295,  1.1295,  1.1295]])\n",
      "4.2734761238098145\n",
      "tensor([[ 0.,  0.,  0.]])\n",
      "---\n",
      "tensor([[ 1.0230,  1.0432,  1.3223]])\n",
      "tensor([[ 1.1295,  1.1295,  1.1295]])\n",
      "4.2734761238098145\n",
      "tensor([[ 0.,  0.,  0.]])\n",
      "---\n",
      "tensor([[ 1.0230,  1.0432,  1.3223]])\n",
      "tensor([[ 1.1295,  1.1295,  1.1295]])\n",
      "4.2734761238098145\n",
      "tensor([[ 0.,  0.,  0.]])\n",
      "---\n",
      "tensor([[ 1.0230,  1.0432,  1.3223]])\n",
      "tensor([[ 1.1295,  1.1295,  1.1295]])\n",
      "4.2734761238098145\n",
      "tensor([[ 0.,  0.,  0.]])\n",
      "---\n",
      "tensor([[ 1.0230,  1.0432,  1.3223]])\n",
      "tensor([[ 1.1295,  1.1295,  1.1295]])\n",
      "4.2734761238098145\n",
      "tensor([[ 0.,  0.,  0.]])\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Testing Binarize:\n",
    "# Create random Tensors to hold input and outputs.\n",
    "x = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "b = Binarize.apply\n",
    "\n",
    "# Forward pass: compute predicted y using operations; we compute\n",
    "# ReLU using our custom autograd operation.\n",
    "for _ in range(10):\n",
    "    y = b(x)\n",
    "    loss = (y - torch.FloatTensor([1,2,3])).pow(2).sum()\n",
    "    loss.backward()\n",
    "\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(loss.item())\n",
    "    # Update weights using gradient descent\n",
    "    with torch.no_grad():\n",
    "        x -= x.grad * 1e-1\n",
    "        print(x.grad)\n",
    "        x.grad.zero_()\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BinaryConvolution2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            # nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(16),\n",
    "            BinaryConvolution2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            # nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # nn.BatchNorm2d(32),\n",
    "        )\n",
    "        # self.fc = nn.Linear(7*7*32, num_classes) \n",
    "        self.fc = BinaryLinear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        # Flatten\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if (i+1) % 300 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    \n",
    "    ###\n",
    "    # Test the model\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc = 100 * correct / total\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(acc))\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [300/1875], Loss: 0.1024\n",
      "Epoch [1/1], Step [600/1875], Loss: 0.0850\n",
      "Epoch [1/1], Step [900/1875], Loss: 0.4488\n",
      "Epoch [1/1], Step [1200/1875], Loss: 0.3311\n",
      "Epoch [1/1], Step [1500/1875], Loss: 0.2197\n",
      "Epoch [1/1], Step [1800/1875], Loss: 0.1284\n",
      "Test Accuracy of the model on the 10000 test images: 95.95 %\n",
      "Epoch [1/1], Step [300/1875], Loss: 0.0669\n",
      "Epoch [1/1], Step [600/1875], Loss: 0.0742\n",
      "Epoch [1/1], Step [900/1875], Loss: 0.1549\n",
      "Epoch [1/1], Step [1200/1875], Loss: 0.1096\n",
      "Epoch [1/1], Step [1500/1875], Loss: 0.0812\n",
      "Epoch [1/1], Step [1800/1875], Loss: 0.0274\n",
      "Test Accuracy of the model on the 10000 test images: 96.42 %\n",
      "Epoch [1/1], Step [300/1875], Loss: 0.1891\n",
      "Epoch [1/1], Step [600/1875], Loss: 0.1422\n",
      "Epoch [1/1], Step [900/1875], Loss: 0.0391\n",
      "Epoch [1/1], Step [1200/1875], Loss: 0.1425\n",
      "Epoch [1/1], Step [1500/1875], Loss: 0.1626\n",
      "Epoch [1/1], Step [1800/1875], Loss: 0.0120\n",
      "Test Accuracy of the model on the 10000 test images: 97.0 %\n",
      "Epoch [1/1], Step [300/1875], Loss: 0.0892\n",
      "Epoch [1/1], Step [600/1875], Loss: 0.0401\n",
      "Epoch [1/1], Step [900/1875], Loss: 0.1351\n",
      "Epoch [1/1], Step [1200/1875], Loss: 0.0660\n",
      "Epoch [1/1], Step [1500/1875], Loss: 0.0978\n",
      "Epoch [1/1], Step [1800/1875], Loss: 0.0872\n",
      "Test Accuracy of the model on the 10000 test images: 96.69 %\n",
      "Epoch [1/1], Step [300/1875], Loss: 0.1167\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-19486c16a039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average performance : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-10a0974e5da8>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idp3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idp3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runs = 5\n",
    "\n",
    "performance = []\n",
    "for _ in range(runs):\n",
    "    performance.append(run_model())\n",
    "    \n",
    "print(\"Average performance : \", np.mean(performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BinaryConvolution2d()\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BinaryConvolution2d()\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): BinaryLinear()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(repr(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCsLKnWEYJgVh5c4wDJOC/H9wdNarTd9QvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1094b7ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
