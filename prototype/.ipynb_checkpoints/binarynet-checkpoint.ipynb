{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import datasets\n",
    "import mxnet as mx\n",
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mnist['train_data']\n",
    "x = x.reshape(x.shape[0], -1)\n",
    "y = mnist['train_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-7-4027bc0391d7>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "<ipython-input-7-4027bc0391d7>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Weights must be of the format (in, hidden)\n",
    "shapes = [784, 10, 10]\n",
    "W = [np.random.randn(shapes[i], shapes[i+1]) for i in range(len(shapes)-1)]\n",
    "\n",
    "def affine(x, w):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    w : (m, k)\n",
    "    out : (n, k)\n",
    "    \"\"\"\n",
    "    return x.dot(w)\n",
    "\n",
    "def affine_(d, x, w):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    w : (m, k)\n",
    "    d : (n, k)\n",
    "    ---\n",
    "    dw : (m, k)\n",
    "    dx : (n, m)\n",
    "    \"\"\"\n",
    "    return {'x': d.dot(w.T), 'w': x.T.dot(d)}\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    out : (n, m)\n",
    "    \"\"\"\n",
    "    return sp.special.expit(x)\n",
    "\n",
    "def sigmoid_(d, x):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    d : (n, m)\n",
    "    ---\n",
    "    dx : (n, m)\n",
    "    \"\"\"\n",
    "    sigm = sp.special.expit(x)\n",
    "    return d * (sigm * (1-sigm))\n",
    "\n",
    "def softmax_ce(x, y):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    y : (n,)\n",
    "    out : () [scalar]\n",
    "    \n",
    "    Equation is 1/n * \\sum_i^n [ -log(e^x_{y_i} / \\sum_j e^x_j) ]\n",
    "    which is equivalently:\n",
    "        \n",
    "        1/n * \\sum_i^n log(\\sum_j e^x_j) - x_{y_i}\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    exp = np.exp(x)\n",
    "    # denominator in original expression, after log\n",
    "    denom = np.log(np.sum(exp, axis=1))\n",
    "    return np.sum(denom - x[np.arange(n), y]) / n\n",
    "\n",
    "def softmax_ce_(x, y):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    y : (n,)\n",
    "    ---\n",
    "    dx : (n, m)\n",
    "    \n",
    "    Back propagation for a single data point is:\n",
    "    \n",
    "    dL_i/dx_{ik} = -1_{k == y_i} + softmax(x_i)_k\n",
    "    \n",
    "    thus, for all data points:\n",
    "    dL/dx_k = 1/n * \\sum_i -1_{k == y_i} + softmax(x_i)_k\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    exp = np.exp(x)\n",
    "    softmax = exp / np.expand_dims(np.sum(exp, axis=1), 1)\n",
    "    softmax[np.arange(n), y] -= 1\n",
    "    return softmax / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 0 : 6.876867122679856\n",
      "loss at 1 : 7.013631379937711\n",
      "loss at 2 : 4.596261785616495\n",
      "loss at 3 : 4.363249107170067\n",
      "loss at 4 : 3.8873468930014394\n",
      "loss at 5 : 3.6919145991737596\n",
      "loss at 6 : 2.826494003209438\n",
      "loss at 7 : 2.7748892824128832\n",
      "loss at 8 : 2.5933439803926954\n",
      "loss at 9 : 2.5035504351202085\n",
      "loss at 10 : 2.5341935165180476\n",
      "loss at 11 : 2.402329000341309\n",
      "loss at 12 : 2.3893226513966037\n",
      "loss at 13 : 2.4420796950719033\n",
      "loss at 14 : 2.3545938522615457\n",
      "loss at 15 : 2.323011233111081\n",
      "loss at 16 : 2.371528087672656\n",
      "loss at 17 : 2.330874031812646\n",
      "loss at 18 : 2.3459483328197415\n",
      "loss at 19 : 2.3017924997511825\n",
      "loss at 20 : 2.2882064239485045\n",
      "loss at 21 : 2.2964727484664778\n",
      "loss at 22 : 2.2941827184049166\n",
      "loss at 23 : 2.317819611626961\n",
      "loss at 24 : 2.331868911761898\n",
      "loss at 25 : 2.327023058450163\n",
      "loss at 26 : 2.3191197515419946\n",
      "loss at 27 : 2.3209160382236003\n",
      "loss at 28 : 2.3155595425514077\n",
      "loss at 29 : 2.315430918217896\n",
      "loss at 30 : 2.3107020506224325\n",
      "loss at 31 : 2.312851308412495\n",
      "loss at 32 : 2.313009345811832\n",
      "loss at 33 : 2.3124786432455755\n",
      "loss at 34 : 2.3122610916353312\n",
      "loss at 35 : 2.3128406071054153\n",
      "loss at 36 : 2.3119650064313304\n",
      "loss at 37 : 2.31215587973871\n",
      "loss at 38 : 2.3095357073916265\n",
      "loss at 39 : 2.282955388079802\n",
      "loss at 40 : 2.2506147846055287\n",
      "loss at 41 : 2.250061679442302\n",
      "loss at 42 : 2.2500491409329038\n",
      "loss at 43 : 2.250048842673396\n",
      "loss at 44 : 2.2500488355257255\n",
      "loss at 45 : 2.2500488353542383\n",
      "loss at 46 : 2.250048835350123\n",
      "loss at 47 : 2.2500488353500243\n",
      "loss at 48 : 2.2500488353500216\n",
      "loss at 49 : 2.2500488353500216\n",
      "loss at 50 : 2.2500488353500216\n",
      "loss at 51 : 2.250048835350022\n",
      "loss at 52 : 2.250048835350022\n",
      "loss at 53 : 2.250048835350022\n",
      "loss at 54 : 2.2500488353500216\n",
      "loss at 55 : 2.2500488353500216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bbaed3b64c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss at {} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-10b845f12d7f>\u001b[0m in \u001b[0;36mb_affine\u001b[0;34m(x, w)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mb_affine_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    # Forward pass\n",
    "    o1 = b_affine(x, W[0])\n",
    "    loss = softmax_ce(o1, y)\n",
    "    print(\"loss at {} : {}\".format(i, loss))\n",
    "    # Backward pass\n",
    "    d = softmax_ce_(o1, y)\n",
    "    d = b_affine_(d, x, W[0])\n",
    "    dw0 = d['w']\n",
    "    W[0] -= dw0 * 1e2\n",
    "    # W[1] -= dw1 * 1e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 6 8 1 2 8 7 8 1] [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(o1, axis=1)[:10], y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple binary NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:75: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:96: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:75: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:96: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:75: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:96: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-5-10b845f12d7f>:75: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "<ipython-input-5-10b845f12d7f>:96: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Weights must be of the format (in, hidden)\n",
    "shapes = [3, 1, 3]\n",
    "W = [np.random.randn(shapes[i], shapes[i+1]) for i in range(len(shapes)-1)]\n",
    "alpha = [np.mean(np.absolute(w)) for w in W]\n",
    "bW = [np.sign(w).astype(np.int8) for w in W]\n",
    "\n",
    "def l1(w):\n",
    "    return np.mean(np.absolute(w))\n",
    "\n",
    "def b(w):\n",
    "    return l1(w) * np.sign(w)\n",
    "\n",
    "def b_affine(x, w):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    w : (m, k)\n",
    "    out : (n, k)\n",
    "    \"\"\"\n",
    "    return x.dot(b(w))\n",
    "\n",
    "def b_affine_(d, x, w):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    w : (m, k)\n",
    "    d : (n, k)\n",
    "    ---\n",
    "    dw : (m, k)\n",
    "    dx : (n, m)\n",
    "    WARNING: Untested!\n",
    "    \"\"\"\n",
    "    # dw_ is binarized w's gradients\n",
    "    # dw is real gradients\n",
    "    dw_ = x.T.dot(d)\n",
    "    signw = np.sign(w)\n",
    "    n = w.size\n",
    "    # Multiplication rule: l1(w) / n * d[sign(w_i)]/dw_i\n",
    "    # print(((-1 <= w) * (w <= 1) * w), dw_)\n",
    "    # dw = ((-1 <= w) * (w <= 1) * w) * l1(w) / n * dw_\n",
    "    dw = ((-1 <= w) * (w <= 1) * w) * l1(w) / n * dw_\n",
    "    # print(dw)\n",
    "    # Multiplication rule: \\sum_j d[l1(w)/n]/dw_i * sign(w_j)\n",
    "    dw += np.sum(dw_ * signw) / n * signw\n",
    "    # dw += 1/n * dw_\n",
    "    return {'x': d.dot(b(w).T), 'w': dw}\n",
    "\n",
    "def b_sigmoid(x):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    out : (n, m)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    return sp.special.expit(x)\n",
    "\n",
    "def b_sigmoid_(d, x):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    d : (n, m)\n",
    "    ---\n",
    "    dx : (n, m)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    sigm = sp.special.expit(x)\n",
    "    return d * (sigm * (1-sigm))\n",
    "\n",
    "def softmax_ce(x, y):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    y : (n,)\n",
    "    out : () [scalar]\n",
    "    \n",
    "    Equation is 1/n * \\sum_i^n [ -log(e^x_{y_i} / \\sum_j e^x_j) ]\n",
    "    which is equivalently:\n",
    "        \n",
    "        1/n * \\sum_i^n log(\\sum_j e^x_j) - x_{y_i}\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    raise NotImplementedError\n",
    "    exp = np.exp(x)\n",
    "    # denominator in original expression, after log\n",
    "    denom = np.log(np.sum(exp, axis=1))\n",
    "    return np.sum(denom - x[np.arange(n), y]) / n\n",
    "\n",
    "def softmax_ce_(x, y):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    y : (n,)\n",
    "    ---\n",
    "    dx : (n, m)\n",
    "    \n",
    "    Back propagation for a single data point is:\n",
    "    \n",
    "    dL_i/dx_{ik} = -1_{k == y_i} + softmax(x_i)_k\n",
    "    \n",
    "    thus, for all data points:\n",
    "    dL/dx_k = 1/n * \\sum_i -1_{k == y_i} + softmax(x_i)_k\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    n = x.shape[0]\n",
    "    exp = np.exp(x)\n",
    "    softmax = exp / np.expand_dims(np.sum(exp, axis=1), 1)\n",
    "    softmax[np.arange(n), y] -= 1\n",
    "    return softmax / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73265667]\n",
      " [ 1.43586153]\n",
      " [-1.55492876]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[-1,2,3]])\n",
    "print(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73265667]\n",
      " [1.43586153]\n",
      " [1.55492876]]\n"
     ]
    }
   ],
   "source": [
    "print(W[0] * np.sign(W[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.24114899]\n",
      " [ 1.24114899]\n",
      " [-1.24114899]]\n"
     ]
    }
   ],
   "source": [
    "print(alpha[0] * bW[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.48229797]]\n"
     ]
    }
   ],
   "source": [
    "print(b_affine(x, W[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73265667]\n",
      " [ 0.        ]\n",
      " [-0.        ]] [[-1.]\n",
      " [ 2.]\n",
      " [ 3.]]\n",
      "[[-0.30311203]\n",
      " [ 0.        ]\n",
      " [-0.        ]]\n"
     ]
    }
   ],
   "source": [
    "d = b_affine_(np.ones((1,1)), x, W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73265667]\n",
      " [ 1.43586153]\n",
      " [-1.55492876]] [[-0.96977869]\n",
      " [-0.66666667]\n",
      " [ 0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "print(W[0], d['w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23712203]\n",
      " [ 0.76919487]\n",
      " [-0.88826209]]\n"
     ]
    }
   ],
   "source": [
    "w0 = W[0] + d['w']\n",
    "print(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(b_affine(x, w0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([[-0.39000329, -0.4149634 , -0.40960516]]), 'w': array([[-1.],\n",
       "        [ 2.],\n",
       "        [ 3.]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine_(np.ones((1,1)), x, W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73265667]\n",
      " [ 0.        ]\n",
      " [-0.        ]] [[-1.]\n",
      " [ 2.]\n",
      " [ 3.]]\n",
      "[[-0.30311203]\n",
      " [ 0.        ]\n",
      " [-0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': array([[ 1.24114899,  1.24114899, -1.24114899]]),\n",
       " 'w': array([[-0.96977869],\n",
       "        [-0.66666667],\n",
       "        [ 0.66666667]])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_affine_(np.ones((1,1)), x, W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
