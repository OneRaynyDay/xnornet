{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import datasets\n",
    "import mxnet as mx\n",
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mnist['train_data']\n",
    "x = x.reshape(x.shape[0], -1)\n",
    "y = mnist['train_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "<input>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "<ipython-input-14-5e39c44c1f8f>:51: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "<ipython-input-14-5e39c44c1f8f>:71: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Weights must be of the format (in, hidden)\n",
    "shapes = [784, 100, 10]\n",
    "W = [np.random.randn(shapes[i], shapes[i+1]) for i in range(len(shapes)-1)]\n",
    "\n",
    "def affine(x, w):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    w : (m, k)\n",
    "    out : (n, k)\n",
    "    \"\"\"\n",
    "    return x.dot(w)\n",
    "\n",
    "def affine_(d, x, w):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    w : (m, k)\n",
    "    d : (n, k)\n",
    "    ---\n",
    "    dw : (m, k)\n",
    "    dx : (n, m)\n",
    "    \"\"\"\n",
    "    return {'x': d.dot(w.T), 'w': x.T.dot(d)}\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    out : (n, m)\n",
    "    \"\"\"\n",
    "    return sp.special.expit(x)\n",
    "\n",
    "def sigmoid_(d, x):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    d : (n, m)\n",
    "    ---\n",
    "    dx : (n, m)\n",
    "    \"\"\"\n",
    "    sigm = sp.special.expit(x)\n",
    "    return d * (sigm * (1-sigm))\n",
    "\n",
    "def softmax_ce(x, y):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    y : (n,)\n",
    "    out : () [scalar]\n",
    "    \n",
    "    Equation is 1/n * \\sum_i^n [ -log(e^x_{y_i} / \\sum_j e^x_j) ]\n",
    "    which is equivalently:\n",
    "        \n",
    "        1/n * \\sum_i^n log(\\sum_j e^x_j) - x_{y_i}\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    exp = np.exp(x)\n",
    "    # denominator in original expression, after log\n",
    "    denom = np.log(np.sum(exp, axis=1))\n",
    "    return np.sum(denom - x[np.arange(n), y]) / n\n",
    "\n",
    "def softmax_ce_(x, y):\n",
    "    \"\"\"\n",
    "    x : (n, m)\n",
    "    y : (n,)\n",
    "    ---\n",
    "    dx : (n, m)\n",
    "    \n",
    "    Back propagation for a single data point is:\n",
    "    \n",
    "    dL_i/dx_{ik} = -1_{k == y_i} + softmax(x_i)_k\n",
    "    \n",
    "    thus, for all data points:\n",
    "    dL/dx_k = 1/n * \\sum_i -1_{k == y_i} + softmax(x_i)_k\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    exp = np.exp(x)\n",
    "    softmax = exp / np.expand_dims(np.sum(exp, axis=1), 1)\n",
    "    softmax[np.arange(n), y] -= 1\n",
    "    return softmax / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 0 : 0.8513821343430952\n",
      "loss at 1 : 0.8882258889421258\n",
      "loss at 2 : 0.8012652944963672\n",
      "loss at 3 : 0.8246505679153368\n",
      "loss at 4 : 0.755178812539145\n",
      "loss at 5 : 0.7695421554257007\n",
      "loss at 6 : 0.7139919293885276\n",
      "loss at 7 : 0.7211841141563288\n",
      "loss at 8 : 0.67806170978656\n",
      "loss at 9 : 0.6801962994386499\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    # Forward pass\n",
    "    o1 = affine(x, W[0])\n",
    "    o2 = sigmoid(o1)\n",
    "    o3 = affine(o2, W[1])\n",
    "    loss = softmax_ce(o3, y)\n",
    "    print(\"loss at {} : {}\".format(i, loss))\n",
    "    # Backward pass\n",
    "    d = softmax_ce_(o3, y)\n",
    "    d = affine_(d, o2, W[1])\n",
    "    dw1 = d['w']\n",
    "    d = d['x']\n",
    "    d = sigmoid_(d, o1)\n",
    "    d = affine_(d, x, W[0])\n",
    "    dw0 = d['w']\n",
    "    W[0] -= dw0 * 10\n",
    "    W[1] -= dw1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4] [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(o3, axis=1)[:10], y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple binary NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
